{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Worldometer-crawler.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"cjQu-Bwm5J5v","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1651130448155,"user_tz":-420,"elapsed":27550,"user":{"displayName":"Lê Kiệt","userId":"01181671526944129545"}},"outputId":"c8a1446a-5187-4954-ff71-9169d9576f1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import requests\n","from bs4 import BeautifulSoup\n","import time\n","import re\n","import os\n","import pandas as pd # Dùng để đọc và hiển thị file csv/tsv\n","from datetime import datetime, timedelta # Dùng để xử lý dữ liệu thời gian\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["url = 'https://www.worldometers.info/coronavirus/'\n","r = requests.get(url)\n","soup = BeautifulSoup(r.text, 'html.parser')"],"metadata":{"id":"CDqKWYQu52Ym","executionInfo":{"status":"ok","timestamp":1651130449674,"user_tz":-420,"elapsed":1526,"user":{"displayName":"Lê Kiệt","userId":"01181671526944129545"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Get columns"],"metadata":{"id":"BlruMRAhkgXm"}},{"cell_type":"code","source":["cols = ['Country, Other', 'Total Cases', 'New Cases', 'Total Deaths', 'New Deaths', 'Total Recovered', 'New Recovered', 'Active Cases', 'Serious, Critical',\n","        'Tot Cases/1M pop', 'Deaths/1M pop', 'Total Tests', 'Tests/1M pop', 'Population']\n","len(cols)        "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VALrTYkxPbI4","executionInfo":{"status":"ok","timestamp":1651130449676,"user_tz":-420,"elapsed":23,"user":{"displayName":"Lê Kiệt","userId":"01181671526944129545"}},"outputId":"281e3d2a-e55f-40c6-f52b-35f2f2782853"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["14"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["## Get rows"],"metadata":{"id":"rtgRZb7skiuJ"}},{"cell_type":"markdown","source":["Ref: https://www.pluralsight.com/guides/extracting-data-html-beautifulsoup "],"metadata":{"id":"TH5a85Mr0rzt"}},{"cell_type":"code","source":["def get_table(which):\n","  '''which: today/yesterday/2 days ago'''\n","  table = soup.find('table', {\"id\": which})\n","  row_0 = table.tbody.find_all('tr', {'style': ''})[0]\n","  row_last = table.find('tbody', {'class': 'total_row_body body_world'})\n","  rows = table.tbody.find_all('tr', {'style': re.compile(r'(^$|^background)')})\n","  rows.insert(0, row_0)\n","  rows.append(row_last)\n","  table_data = []\n","\n","  for row in rows:\n","    j=0\n","    t_row = {}\n","    for td in row.find_all(\"td\")[1:]: # bỏ qua '#STT'\n","      if j == len(cols): # bỏ thẻ 'td' thừa\n","        break\n","      t_row[cols[j]] = td.text.replace('\\n', '').strip()\n","      j+=1\n","    table_data.append(t_row)\n","  df = pd.DataFrame(table_data) # convert table_data to dataframe\n","  return df"],"metadata":{"id":"uLeGEAhC3ACU","executionInfo":{"status":"ok","timestamp":1651130449678,"user_tz":-420,"elapsed":19,"user":{"displayName":"Lê Kiệt","userId":"01181671526944129545"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["which = ['main_table_countries_today', # today\n","         'main_table_countries_yesterday', # yesterday\n","         'main_table_countries_yesterday2'] # 2 days ago\n","\n","for i in range(len(which)):\n","  d = (datetime.today() - timedelta(days=i)).strftime('%d-%m-%Y')  \n","  df = get_table(which[i])\n","  df.to_csv(f'/content/drive/MyDrive/Colab Notebooks/Lab01/Worldometer-data/table_{d}_raw.csv')     "],"metadata":{"id":"AmX83PPl3tPd","executionInfo":{"status":"ok","timestamp":1651130451086,"user_tz":-420,"elapsed":1424,"user":{"displayName":"Lê Kiệt","userId":"01181671526944129545"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["---"],"metadata":{"id":"c--SOwhSqD6X"}},{"cell_type":"markdown","source":["# Cào data-continent cho mỗi country để phục vụ cho quy trình preprocess"],"metadata":{"id":"v2NgMfxetHH-"}},{"cell_type":"code","source":["if not os.path.exists('/content/drive/MyDrive/Colab Notebooks/Lab01/continents.csv'):\n","  table = soup.find('table', {'id': 'main_table_countries_today'})\n","  row_0 = table.tbody.find_all('tr', {'style': ''})[0]\n","  row_last = table.find('tbody', {'class': 'total_row_body body_world'})\n","  rows = table.tbody.find_all('tr', {'style': re.compile(r'(^$|^background)')})\n","  rows.insert(0, row_0)\n","  rows.append(row_last)\n","  continent = {}\n","\n","  for row in rows:\n","    row_info = row.find_all(\"td\")[1:]\n","    country = row_info[0].text.replace('\\n', '').strip()\n","\n","    for td in row_info: \n","      try:\n","        if td['data-continent'] != '': \n","          continent[country] = td['data-continent']\n","          break\n","      except:\n","        continue\n","  continent\n","\n","  continent_df = pd.DataFrame.from_dict(continent, orient='index', columns=['continent'])\n","  continent_df.to_csv('/content/drive/MyDrive/Colab Notebooks/Lab01/continents.csv')"],"metadata":{"id":"usv_Mq4Zx9mW","executionInfo":{"status":"ok","timestamp":1651130451088,"user_tz":-420,"elapsed":9,"user":{"displayName":"Lê Kiệt","userId":"01181671526944129545"}}},"execution_count":6,"outputs":[]}]}